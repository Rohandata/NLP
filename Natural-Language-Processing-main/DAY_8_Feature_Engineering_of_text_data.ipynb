{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DAY-8 Feature Engineering of text data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNabjbuVIVhpgOp3ZgtVCtY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajay-Sai-Kiran/Natural-Language-Processing/blob/main/DAY_8_Feature_Engineering_of_text_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering of Text Data"
      ],
      "metadata": {
        "id": "Zso41lkY-0Ja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction mainly has two main methods: \n",
        "\n",
        "bag-of-words, and \n",
        "\n",
        "word embedding. \n",
        "\n",
        "Both of them are commonly used and has different approaches. I will explain both of them and differences between them"
      ],
      "metadata": {
        "id": "S6BXYCCY_ATh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bag of Words with TF-IDF\n",
        "\n",
        "\n",
        "Bag-of-Words with TF-IDF is a traditional and simple feature extraction method in natural language processing. Bag-of-Words is a “representation model” of text data and TF-IDF is a “calculation method” to score an importance of words in a document."
      ],
      "metadata": {
        "id": "zbiqEWWHCz2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample sentences.\n",
        "sentences = [\n",
        "    \"Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks\",\n",
        "    \"Machine learning (ML) is a type of artificial intelligence (AI) that allows software applications to become more accurate at predicting outcomes without being explicitly programmed to do so\",\n",
        "    \"You are a very good software engineer, engineer.\",\n",
        "]\n",
        "\n",
        "# Create CountVectorizer, which create bag-of-words model.\n",
        "# stop_words : Specify language to remove stopwords. \n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "# Learn vocabulary in sentences. \n",
        "vectorizer.fit(sentences)\n",
        "\n",
        "# Get dictionary. \n",
        "vectorizer.get_feature_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iQl3WfXC_Ed",
        "outputId": "fb721fc7-1e27-4ebd-968b-26f5cde5a7df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['accurate',\n",
              " 'ai',\n",
              " 'allows',\n",
              " 'applications',\n",
              " 'artificial',\n",
              " 'communicate',\n",
              " 'computers',\n",
              " 'engineer',\n",
              " 'explicitly',\n",
              " 'good',\n",
              " 'helps',\n",
              " 'humans',\n",
              " 'intelligence',\n",
              " 'language',\n",
              " 'learning',\n",
              " 'machine',\n",
              " 'ml',\n",
              " 'natural',\n",
              " 'outcomes',\n",
              " 'predicting',\n",
              " 'processing',\n",
              " 'programmed',\n",
              " 'related',\n",
              " 'scales',\n",
              " 'software',\n",
              " 'tasks',\n",
              " 'type']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform each sentences in vector space.\n",
        "vector = vectorizer.transform(sentences)\n",
        "vector_spaces = vector.toarray()\n",
        "\n",
        "vector_spaces"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRIea_HJDC82",
        "outputId": "553d73f3-2276-4646-db68-c5ee37a8f0b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "        1, 1, 0, 1, 0],\n",
              "       [1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        0, 0, 1, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show sentences and vector space representation.\n",
        "for i, v in zip(sentences, vector_spaces):\n",
        "    print(i)\n",
        "    print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZdeDLcqDFVW",
        "outputId": "5f660964-d52f-49bd-d77d-f0e0c0d4c7eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks\n",
            "[0 0 0 0 0 1 1 0 0 0 1 1 0 3 0 0 0 1 0 0 1 0 1 1 0 1 0]\n",
            "Machine learning (ML) is a type of artificial intelligence (AI) that allows software applications to become more accurate at predicting outcomes without being explicitly programmed to do so\n",
            "[1 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1]\n",
            "You are a very good software engineer, engineer.\n",
            "[0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "sentences = [\n",
        "    \"Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks\",\n",
        "    \"Machine learning (ML) is a type of artificial intelligence (AI) that allows software applications to become more accurate at predicting outcomes without being explicitly programmed to do so\",\n",
        "    \"You are a very good software engineer, engineer.\",\n",
        "]\n",
        "\n",
        "# Create TfidfVectorizer.\n",
        "# stop_words : Get rid of english stop words. \n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Learn vocabulary from sentences. \n",
        "vectorizer.fit(sentences)\n",
        "\n",
        "# Get vocabularies.\n",
        "vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLQ_QaClDKGl",
        "outputId": "91916de9-efd2-4626-e604-32e330974f7f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accurate': 0,\n",
              " 'ai': 1,\n",
              " 'allows': 2,\n",
              " 'applications': 3,\n",
              " 'artificial': 4,\n",
              " 'communicate': 5,\n",
              " 'computers': 6,\n",
              " 'engineer': 7,\n",
              " 'explicitly': 8,\n",
              " 'good': 9,\n",
              " 'helps': 10,\n",
              " 'humans': 11,\n",
              " 'intelligence': 12,\n",
              " 'language': 13,\n",
              " 'learning': 14,\n",
              " 'machine': 15,\n",
              " 'ml': 16,\n",
              " 'natural': 17,\n",
              " 'outcomes': 18,\n",
              " 'predicting': 19,\n",
              " 'processing': 20,\n",
              " 'programmed': 21,\n",
              " 'related': 22,\n",
              " 'scales': 23,\n",
              " 'software': 24,\n",
              " 'tasks': 25,\n",
              " 'type': 26}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform to document-term matrix\n",
        "vector_spaces = vectorizer.transform(sentences)\n",
        "vector_spaces.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF2kyJIHDLpF",
        "outputId": "8ed5533e-4066-4479-8db9-cf078f5093c8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.23570226, 0.23570226, 0.        , 0.        , 0.        ,\n",
              "        0.23570226, 0.23570226, 0.        , 0.70710678, 0.        ,\n",
              "        0.        , 0.        , 0.23570226, 0.        , 0.        ,\n",
              "        0.23570226, 0.        , 0.23570226, 0.23570226, 0.        ,\n",
              "        0.23570226, 0.        ],\n",
              "       [0.26190578, 0.26190578, 0.26190578, 0.26190578, 0.26190578,\n",
              "        0.        , 0.        , 0.        , 0.26190578, 0.        ,\n",
              "        0.        , 0.        , 0.26190578, 0.        , 0.26190578,\n",
              "        0.26190578, 0.26190578, 0.        , 0.26190578, 0.26190578,\n",
              "        0.        , 0.26190578, 0.        , 0.        , 0.19918609,\n",
              "        0.        , 0.26190578],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.84678897, 0.        , 0.42339448,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.32200242,\n",
              "        0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, v in zip(sentences, vector_spaces):\n",
        "    print(i)\n",
        "    print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maJ4MDBHDPA2",
        "outputId": "6bd3849b-3edf-456d-aa61-b2e59e7421a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks\n",
            "  (0, 25)\t0.2357022603955158\n",
            "  (0, 23)\t0.2357022603955158\n",
            "  (0, 22)\t0.2357022603955158\n",
            "  (0, 20)\t0.2357022603955158\n",
            "  (0, 17)\t0.2357022603955158\n",
            "  (0, 13)\t0.7071067811865475\n",
            "  (0, 11)\t0.2357022603955158\n",
            "  (0, 10)\t0.2357022603955158\n",
            "  (0, 6)\t0.2357022603955158\n",
            "  (0, 5)\t0.2357022603955158\n",
            "Machine learning (ML) is a type of artificial intelligence (AI) that allows software applications to become more accurate at predicting outcomes without being explicitly programmed to do so\n",
            "  (0, 26)\t0.26190577641518953\n",
            "  (0, 24)\t0.19918609370383894\n",
            "  (0, 21)\t0.26190577641518953\n",
            "  (0, 19)\t0.26190577641518953\n",
            "  (0, 18)\t0.26190577641518953\n",
            "  (0, 16)\t0.26190577641518953\n",
            "  (0, 15)\t0.26190577641518953\n",
            "  (0, 14)\t0.26190577641518953\n",
            "  (0, 12)\t0.26190577641518953\n",
            "  (0, 8)\t0.26190577641518953\n",
            "  (0, 4)\t0.26190577641518953\n",
            "  (0, 3)\t0.26190577641518953\n",
            "  (0, 2)\t0.26190577641518953\n",
            "  (0, 1)\t0.26190577641518953\n",
            "  (0, 0)\t0.26190577641518953\n",
            "You are a very good software engineer, engineer.\n",
            "  (0, 24)\t0.3220024178194947\n",
            "  (0, 9)\t0.42339448341195934\n",
            "  (0, 7)\t0.8467889668239187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word Embedding"
      ],
      "metadata": {
        "id": "ylAd2wvIDmOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embedding is one of the document representation in vector space model. It captures contexts and semantics of word unlike Bag-of-Words model. Bag-of-Words only represents number of occurrence of words in document without any relationships and contexts. On the other hand, Word embedding preserves contexts and relationships of words so that it detects similar words more accurately."
      ],
      "metadata": {
        "id": "2WSoyAw8Dq0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word2vec\n",
        "\n",
        "Word2vec is one of the most popular implementation of word embedding, which is invented by Google in 2013. It describes word embedding with two-layer shallow neural networks in order to recognize context meanings.\n",
        "\n",
        "Word2vec is good at grouping similar words and making highly accurate guesses about meaning of words based on contexts. \n",
        "It has two different algorithms inside:\n",
        "\n",
        "\n",
        "CBoW(Continuous Bag-of-Words) and \n",
        "skip gram model."
      ],
      "metadata": {
        "id": "1s7yQjI1DxOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Get document data.\n",
        "common_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGYHNy0nDlol",
        "outputId": "89ce3ebd-b124-45ef-fe86-38302c54900d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['human', 'interface', 'computer'],\n",
              " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
              " ['eps', 'user', 'interface', 'system'],\n",
              " ['system', 'human', 'system', 'eps'],\n",
              " ['user', 'response', 'time'],\n",
              " ['trees'],\n",
              " ['graph', 'trees'],\n",
              " ['graph', 'minors', 'trees'],\n",
              " ['graph', 'minors', 'survey']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec modeling. \n",
        "model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Get specified vocabulary's vector. \n",
        "model.wv[\"human\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPBV34LrD8_v",
        "outputId": "86e03b46-8270-4b01-85c3-e718bb70f8c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.9272060e-04,  1.0017658e-03,  1.7501498e-04, -8.6333523e-05,\n",
              "        4.4604125e-03, -3.5663932e-03,  7.0894028e-05, -2.4404787e-03,\n",
              "       -3.5875663e-03,  1.1043018e-03, -2.7340502e-03, -1.8319436e-03,\n",
              "        7.5065304e-04, -1.2301384e-03,  4.8667877e-03,  2.4788410e-03,\n",
              "       -7.2513492e-04,  3.9498815e-03,  6.8107276e-04,  3.1631251e-03,\n",
              "       -1.7963970e-03,  9.0599572e-04, -1.5415214e-03, -2.0505588e-03,\n",
              "       -4.8715952e-03,  4.7385395e-03,  2.5972070e-03, -3.4232132e-04,\n",
              "       -9.5266529e-04, -1.9619314e-03,  1.3030939e-03,  1.7025197e-03,\n",
              "        6.5801857e-04,  4.1995966e-03, -2.3826668e-03, -1.5172569e-04,\n",
              "       -4.9485448e-03,  4.7071259e-03, -3.2198715e-03,  3.7962880e-03,\n",
              "        1.5945356e-04,  2.6255578e-03, -1.5805045e-03, -5.7039055e-04,\n",
              "        1.4873416e-03, -2.1401814e-03,  3.1070798e-03,  4.4205035e-03,\n",
              "        2.0905412e-03,  2.3956869e-03,  2.9179810e-03, -1.8138132e-03,\n",
              "       -1.5461032e-03, -2.3744792e-04,  9.6716528e-04,  3.4993188e-03,\n",
              "        6.5683713e-04, -2.0874497e-03,  2.0353028e-04,  5.6498847e-04,\n",
              "        2.4828529e-03,  2.9351958e-03, -2.8785984e-03, -4.1963379e-03,\n",
              "       -4.6187281e-03,  2.7319815e-03,  4.4625057e-03, -2.7469927e-03,\n",
              "        5.3155836e-05,  1.9906056e-03, -2.4835079e-03,  8.3590865e-05,\n",
              "        3.4454326e-05,  2.9157824e-03,  4.0384042e-03, -3.5414714e-03,\n",
              "        4.3056882e-03,  3.0051181e-03, -1.0585214e-03,  2.6265269e-03,\n",
              "        4.4574952e-03,  7.4971281e-04, -2.4425343e-04, -2.2598652e-03,\n",
              "       -2.6928736e-03, -2.2563578e-05,  4.6429294e-03, -3.1292124e-03,\n",
              "        2.0844254e-03,  4.2755948e-03, -2.3059754e-03, -3.6270395e-03,\n",
              "        9.3519790e-05, -4.1929451e-03, -1.5439435e-03, -2.5775149e-03,\n",
              "        1.7677282e-03, -4.3247952e-03,  8.8017090e-04,  9.9152757e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"human\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8nu79g9EBi1",
        "outputId": "1466e5fe-e4f0-4bb6-ba41-98a1476e5f54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('user', 0.12816676497459412),\n",
              " ('interface', 0.1062312126159668),\n",
              " ('eps', 0.09679573774337769),\n",
              " ('computer', 0.09228645265102386),\n",
              " ('minors', 0.07000488042831421),\n",
              " ('survey', 0.05878273397684097),\n",
              " ('response', 0.022046033293008804),\n",
              " ('trees', 0.0005789585411548615),\n",
              " ('system', -0.020276952534914017),\n",
              " ('graph', -0.021966716274619102)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2kCajqy5EFad"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}