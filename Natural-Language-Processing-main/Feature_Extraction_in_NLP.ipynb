{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Extraction in NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP55IkjiRwqQ+VX2vQV3BtT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaysaikiran2208/Natural-Language-Processing/blob/main/Feature_Extraction_in_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h34PRB4jFtX6"
      },
      "source": [
        "#**Feature** **Extraction** **in** ***NLP***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO9sxLFmF443"
      },
      "source": [
        "Machine Learning algorithms learn from a pre-defined set of features from the training data to produce output for the test data. But the main problem in working with language processing is that machine learning algorithms cannot work on the raw text directly. So, we need some feature extraction techniques to convert text into a matrix(or vector) of features.\n",
        "Some of the most popular methods of feature extraction are :\n",
        "\n",
        "      1.Bag-of-Words\n",
        "      2.TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRBE7zd0AaUC"
      },
      "source": [
        "#Bag of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqB_lV4MASGS"
      },
      "source": [
        "A bag-of-words model, or BoW for short, is a way of extracting features from text for use in modeling, such as with machine learning algorithms.\n",
        "\n",
        "The approach is very simple and flexible, and can be used in a myriad of ways for extracting features from documents.\n",
        "\n",
        "A bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n",
        "\n",
        "    1.A vocabulary of known words.\n",
        "    2.A measure of the presence of known words.\n",
        "    \n",
        "It is called a “bag” of words, because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSyOzAze6Bt6"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQfEnQgz6aX0",
        "outputId": "c63757ff-6842-4b15-d1ae-a4bf39d2ed9f"
      },
      "source": [
        "paragraph=str(input(\"Enter the paragraph:\"))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the paragraph:Parents remain very conscious regarding their child’s learning and development. They try to do everything good for their children. When children learn a language in their school days English, parents want to hear simple sentences in English. They love to see their kid speaking a foreign language fluently.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpvXTyOa-QUF",
        "outputId": "80c242f6-2743-4a1c-be94-45f208e2d959"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_rx5kcd8MCU"
      },
      "source": [
        "wordnet=WordNetLemmatizer()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q8NlwBo8UAc",
        "outputId": "61633013-a42a-4d1b-bbfc-433a770911f5"
      },
      "source": [
        "sentences=nltk.sent_tokenize(paragraph)\n",
        "finaltext=[]\n",
        "for i in range(len(sentences)):\n",
        "  review=re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "  review=[wordnet.lemmatize(word) for word in review if word not in set(stopwords.words(\"english\"))]\n",
        "  review=\" \".join(review)\n",
        "  finaltext.append(review)\n",
        "print(finaltext)    "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['parent remain conscious regarding child learning development', 'try everything good child', 'child learn language school day english parent want hear simple sentence english', 'love see kid speaking foreign language fluently']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McY03FO0_1-v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyfmeSni9_o6",
        "outputId": "f27de0c4-1e3d-48a5-a812-19ec065a3270"
      },
      "source": [
        "#creating the Bag of words model\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "bag=cv.fit_transform(finaltext).toarray()\n",
        "print(bag)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [1 0 1 0 2 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1]\n",
            " [0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHZa51H7Fg_0"
      },
      "source": [
        "#TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SuPcGFFFkVy"
      },
      "source": [
        "TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsXIhRWYC2Ju",
        "outputId": "fb03cb5c-7412-4b64-9a28-ffba5b57d9bc"
      },
      "source": [
        "paragraph=str(input(\"Enter the paragraph:\"))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the paragraph:A paragraph is a group of words put together to form a group that is usually longer than a sentence. Paragraphs are often made up of several sentences. There are usually between three and eight sentences. Paragraphs can begin with an indentation (about five spaces), or by missing a line out, and then starting again.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY3k5McaC4wK"
      },
      "source": [
        "wordnet=WordNetLemmatizer()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySTJ6Mvf_TSu",
        "outputId": "96bd0c48-cd54-4e57-fc7e-d42d10bfb33f"
      },
      "source": [
        "sentences=nltk.sent_tokenize(paragraph)\n",
        "finaltext=[]\n",
        "for i in range(len(sentences)):\n",
        "  review=re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "  review=[wordnet.lemmatize(word) for word in review if word not in set(stopwords.words(\"english\"))]\n",
        "  review=\" \".join(review)\n",
        "  finaltext.append(review)\n",
        "print(finaltext)    "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['paragraph group word put together form group usually longer sentence', 'paragraph often made several sentence', 'usually three eight sentence', 'paragraph begin indentation five space missing line starting']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afXdwtTKDDkj"
      },
      "source": [
        "#Creating the TF-IDF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs-pfBoRDNYq"
      },
      "source": [
        "from sklearn.feature_extraction.text import  TfidfVectorizer"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAtXtCmyDT3K"
      },
      "source": [
        "cv=TfidfVectorizer()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzdIhEuVDX96"
      },
      "source": [
        "tfidf=cv.fit_transform(finaltext).toarray()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gv2uvoFDew8",
        "outputId": "3c6b2368-c704-4ff9-e918-87bce7ccbaf0"
      },
      "source": [
        "print(tfidf)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.30954541 0.61909081 0.\n",
            "  0.         0.30954541 0.         0.         0.         0.19757882\n",
            "  0.30954541 0.19757882 0.         0.         0.         0.\n",
            "  0.30954541 0.24404915 0.30954541]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.51199172 0.         0.51199172 0.32679768\n",
            "  0.         0.32679768 0.51199172 0.         0.         0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.57457953 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.36674667 0.         0.         0.         0.57457953\n",
            "  0.         0.4530051  0.        ]\n",
            " [0.36742339 0.         0.36742339 0.         0.         0.36742339\n",
            "  0.36742339 0.         0.         0.36742339 0.         0.23452159\n",
            "  0.         0.         0.         0.36742339 0.36742339 0.\n",
            "  0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIvqBuUoDkua"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb4QuZTHDuVC"
      },
      "source": [
        "tfIdfVectorizer=TfidfVectorizer()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_7sZdk0DyZQ"
      },
      "source": [
        "tfIdf=tfIdfVectorizer.fit_transform(finaltext)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MetRttl2D8Wq"
      },
      "source": [
        "df=pd.DataFrame(tfIdf[3].T.todense(),index=tfIdfVectorizer.get_feature_names(),columns=[\"TF*IDF\"])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k7nym1SEUTN"
      },
      "source": [
        "df=df.sort_values(\"TF*IDF\",ascending=False)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3CdeJB1EZMa",
        "outputId": "411c43d2-5fb0-4df2-e323-a6664dd78446"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               TF*IDF\n",
            "begin        0.367423\n",
            "five         0.367423\n",
            "indentation  0.367423\n",
            "line         0.367423\n",
            "starting     0.367423\n",
            "missing      0.367423\n",
            "space        0.367423\n",
            "paragraph    0.234522\n",
            "sentence     0.000000\n",
            "usually      0.000000\n",
            "together     0.000000\n",
            "three        0.000000\n",
            "several      0.000000\n",
            "often        0.000000\n",
            "put          0.000000\n",
            "eight        0.000000\n",
            "made         0.000000\n",
            "longer       0.000000\n",
            "group        0.000000\n",
            "form         0.000000\n",
            "word         0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}